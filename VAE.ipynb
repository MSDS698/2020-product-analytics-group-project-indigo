{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries and defining some helper functions...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import ctypes.util\n",
    "orig_ctypes_util_find_library = ctypes.util.find_library\n",
    "def proxy_find_library(lib):\n",
    "    if lib == 'fluidsynth':\n",
    "        return 'libfluidsynth.so.1'\n",
    "    else:\n",
    "        return orig_ctypes_util_find_library(lib)\n",
    "ctypes.util.find_library = proxy_find_library\n",
    "\n",
    "\n",
    "print('Importing libraries and defining some helper functions...')\n",
    "\n",
    "from google.colab import files\n",
    "import magenta.music as mm\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Necessary until pyfluidsynth is updated (>1.2.5).\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "def play(note_sequence):\n",
    "    mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
    "\n",
    "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
    "                assert_same_length=True, temperature=0.5,\n",
    "                individual_duration=4.0):\n",
    "    \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
    "    note_sequences = model.interpolate(\n",
    "      start_seq, end_seq,num_steps=num_steps, length=max_length,\n",
    "      temperature=temperature,\n",
    "      assert_same_length=assert_same_length)\n",
    "\n",
    "#     print('Start Seq Reconstruction')\n",
    "#     play(note_sequences[0])\n",
    "#     print('End Seq Reconstruction')\n",
    "#     play(note_sequences[-1])\n",
    "#     print('Mean Sequence')\n",
    "#     play(note_sequences[num_steps // 2])\n",
    "#     print('Start -> End Interpolation')\n",
    "    interp_seq = mm.sequences_lib.concatenate_sequences(\n",
    "      note_sequences, [individual_duration] * len(note_sequences))\n",
    "#     play(interp_seq)\n",
    "#     mm.plot_sequence(interp_seq)\n",
    "    return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
    "\n",
    "def download(note_sequence, filename):\n",
    "    mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
    "    files.download(filename)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import magenta\n",
    "import fluidsynth as fluidsynth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, HierarchicalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 256, 'z_size': 512, 'free_bits': 256, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [1024, 1024], 'enc_rnn_size': [2048, 2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048, 2048]\n",
      "\n",
      "INFO:tensorflow:\n",
      "Hierarchical Decoder:\n",
      "  input length: 256\n",
      "  level output lengths: [16, 16]\n",
      "\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [1024, 1024]\n",
      "\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [1024, 1024]\n",
      "\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [1024, 1024]\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./VAE/checkpoints/trio_16bar_hierdec.ckpt\n",
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, MultiOutCategoricalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 256, 'z_size': 512, 'free_bits': 0.0, 'max_beta': 1.0, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [2048, 2048, 2048], 'enc_rnn_size': [2048, 2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048, 2048]\n",
      "\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [2048, 2048, 2048]\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from ./VAE/checkpoints/trio_16bar_flat.ckpt\n"
     ]
    }
   ],
   "source": [
    "trio_models = {}\n",
    "hierdec_trio_16bar_config = configs.CONFIG_MAP['hierdec-trio_16bar']\n",
    "    trio_models['hierdec_trio_16bar'] = TrainedModel(hierdec_trio_16bar_config, batch_size=4, checkpoint_dir_or_path='./VAE/checkpoints/trio_16bar_hierdec.ckpt')\n",
    "\n",
    "flat_trio_16bar_config = configs.CONFIG_MAP['flat-trio_16bar']\n",
    "trio_models['baseline_flat_trio_16bar'] = TrainedModel(flat_trio_16bar_config, batch_size=4, checkpoint_dir_or_path='./VAE/checkpoints/trio_16bar_flat.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hierdec_trio_16bar': <magenta.models.music_vae.trained_model.TrainedModel at 0x17a05aa90>,\n",
       " 'baseline_flat_trio_16bar': <magenta.models.music_vae.trained_model.TrainedModel at 0x1b868a090>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trio_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#@title Option 1: Use example MIDI files for interpolation endpoints.\n",
    "input_trio_midi_data = [\n",
    "    tf.gfile.Open(fn, 'rb').read()\n",
    "    for fn in sorted(tf.gfile.Glob('./VAE/midi/trio_16bar*.mid'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_trio_midi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Extract trios from MIDI files. This will extract all unique 16-bar trios using a sliding window with a stride of 1 bar.\n",
    "trio_input_seqs = [mm.midi_to_sequence_proto(m) for m in input_trio_midi_data]\n",
    "extracted_trios = []\n",
    "for ns in trio_input_seqs:\n",
    "    extracted_trios.extend(\n",
    "        hierdec_trio_16bar_config.data_converter.from_tensors(\n",
    "          hierdec_trio_16bar_config.data_converter.to_tensors(ns)[1]))\n",
    "# for i, ns in enumerate(extracted_trios):\n",
    "#     print(\"Trio\", i)\n",
    "#     play(ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Compute the reconstructions and mean of the two trios, selected from the previous cell.\n",
    "trio_interp_model = \"hierdec_trio_16bar\" #@param [\"hierdec_trio_16bar\", \"baseline_flat_trio_16bar\"]\n",
    "\n",
    "start_trio = 0 #@param {type:\"integer\"}\n",
    "end_trio = 1 #@param {type:\"integer\"}\n",
    "start_trio = extracted_trios[start_trio]\n",
    "end_trio = extracted_trios[end_trio]\n",
    "\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "trio_16bar_mean = interpolate(trio_models[trio_interp_model], start_trio, end_trio, num_steps=3, max_length=256, individual_duration=32, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hierdec_trio_16bar_mean.mid'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%s_mean.mid' % trio_interp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optionally download mean MIDI file.\n",
    "note_sequence_to_midi_file(trio_16bar_mean, '%s_mean.mid' % trio_interp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_sequence_to_midi_file(sequence, output_file,\n",
    "                               drop_events_n_seconds_after_last_note=None):\n",
    "    \"\"\"\n",
    "    Convert NoteSequence to a MIDI file on disk.\n",
    "    Time is stored in the NoteSequence in absolute values (seconds) as opposed to\n",
    "    relative values (MIDI ticks). When the NoteSequence is translated back to\n",
    "    MIDI the absolute time is retained. The tempo map is also recreated.\n",
    "    Args:\n",
    "    sequence: A NoteSequence.\n",
    "    output_file: String path to MIDI file that will be written.\n",
    "    drop_events_n_seconds_after_last_note: Events (e.g., time signature changes)\n",
    "        that occur this many seconds after the last note will be dropped. If\n",
    "        None, then no events will be dropped.\n",
    "    \"\"\"\n",
    "    pretty_midi_object = mm.midi_io.note_sequence_to_pretty_midi(sequence, drop_events_n_seconds_after_last_note)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile() as temp_file:\n",
    "        pretty_midi_object.write(temp_file)\n",
    "        # Before copying the file, flush any contents\n",
    "        temp_file.flush()\n",
    "        # And back the file position to top (not need for Copy but for certainty)\n",
    "        temp_file.seek(0)\n",
    "        tf.gfile.Copy(temp_file.name, output_file, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Compute the reconstructions and mean of the two trios, selected from the previous cell.\n",
    "trio_interp_model = \"hierdec_trio_16bar\" #@param [\"hierdec_trio_16bar\", \"baseline_flat_trio_16bar\"]\n",
    "\n",
    "start_trio = 0 #@param {type:\"integer\"}\n",
    "end_trio = 1 #@param {type:\"integer\"}\n",
    "start_trio = extracted_trios[start_trio]\n",
    "end_trio = extracted_trios[end_trio]\n",
    "\n",
    "temperature = 0.5 #@param {type:\"slider\", min:0.1, max:1.5, step:0.1}\n",
    "trio_16bar_mean = interpolate(trio_models[trio_interp_model], start_trio, end_trio, num_steps=3, max_length=256, individual_duration=32, temperature=temperature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
